\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2017
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2017}

\usepackage{nips_2017}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2017}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\title{Learning Neural Markers of Schizophrenia Disorder Using Recurrent Neural Networks}


\author{
  David S.~Hippocampus\thanks{Use footnote for providing further
    information about author (webpage, alternative
    address)---\emph{not} for acknowledging funding agencies.} \\
  Department of Computer Science\\
  Cranberry-Lemon University\\
  Pittsburgh, PA 15213 \\
  \texttt{hippo@cs.cranberry-lemon.edu} \\
  %% examples of more authors
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
... Here we propose a new method based on recurrent-convolutional neural networks to automatically learn useful representations from short segments of fMRI recordings...
\end{abstract}

\section{Introduction}

\section{Related Work}

\section{Methods}

\subsection{Dataset}

\subsection{Training Details}
\label{training_details}
\subsection{Data Preparation}

\section*{Results}

We investigated the effectiveness of LSTM and R-CNNs in capturing the temporal and spatial structure of the fMRI data in order to distinguish between normal and schizophrenic patients. LSTM and R-CNN models both performed better than the baseline model. Our best LSTM model performed slightly better than our R-CNN model (~1\%). Additionally, we explored the impact of length of the samples on the performance of the trained network (Figure ??). We found that larger time windows improved the accuracy in all tested models. For the R-CNN models we experimented with different architectures, in order to determine whether more convolutions would produce better generalization and thereby improve overall accuracy. 

\begin{table}[]
\centering
\caption{Comparison of different model architectures and time-windows on the AO dataset.}
\label{table_1}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\textbf{Model}           & \multicolumn{2}{c|}{\textbf{LSTM}} & \textbf{RCNN (2, 1)} & \multicolumn{2}{c|}{\textbf{RCNN (1, 2)}} & \textbf{RCNN (2, 2, 1)} \\ \hline
\textbf{Window Size}      & 16   & 64   & 64    &16    & 64    & 64           \\ \hline
\textbf{Test Performance} & 63   & 64   & 64    & 61      & -           & 63      \\  \hline      
\end{tabular}
\end{table}


We evaluate LSTM and recurrent convolutional neural network models using the configurations in table 1. We trained the models with the non-working AO task dataset. Table 2 shows the number of parameters used by each type of architecture, and the corresponding error achieved on the test set.

The best recurrent convolutional model was obtained with architecture X containing two back-to-back convolutions in the first layer, one convolution in the second layer, and two back-to-back LSTMs in the third layer. We compared results using both 16 and 64 time-window samples while keeping the batch size fixed at 64 samples. For the model using 64 time windows, we noticed a significant improvement of 5\% in classification accuracy.

Comparing the performance of the baseline model and deep learning, the test scores of LSTM and RCNN were 17.5\% better than linear SVM.

\section{Discussion}
A key challenge in dealing with neuroimaging data comes from the inter- and intra-subject variability that any robust diagnosis system should be robust to. A prominent cause of these variabilities are due to small differences in the functional cortical mapping between individuals which calls for neural markers that are position and scale invariant. We applied several neural network architectures to learn invariant markers for schizophrenia disorder from a large-scale fMRI dataset. While both of these methods achieved remarkable accuracy in distinguishing between schizophrenic and control subjects, they fell short of reaching the same level as hand designed connectivity features \citep{Gheiratmand2017}.


\subsubsection*{Acknowledgments}

Data used for this study were downloaded from the Function BIRN Data Repository (http://fbirnbdr.birncommunity.org:8080/BDR/), supported by grants to the Function BIRN (U24-RR021992) Testbed funded by the National Center for Research Resources at the National Institutes of Health, U.S.A. This work used the Extreme Science and Engineering Discovery Environment (XSEDE) XStream at through allocation TG-MCB090174. We acknowledge funding support from the Graduate Assistance in Areas of National Need (GAANN) fellowship and the NSF Award 1443054 (SPIDAL). 

\bibliography{nips2017_workshop}
\bibliographystyle{nips2017_workshop}

\end{document}
